# the port for internal communication
#transport.tcp.port=9300

# the port to be accessed through http
#http.port=9200

# the host to search for elastic search cluster nodes
network.host=127.0.0.1

# disable network
node.local=true

# allow dynamic scripts from the users
script.disable_dynamic=false

# the path to were the index is stored
path.data=elastic-search-data

# the name of the cluster
cluster.name=ingrid

# offer access through http, which can be used with kibana and normal REST calls
http.enabled=false

# define this node as one, which contains data
node.data=true

# define this node as a master node
node.master=true

# define the number of shards to be used
index.number_of_shards=1

# define how many replicas are created (0 = none)
index.number_of_replicas=0

# the name of the index
index.name=dsc

# the name of the type within the index
index.type=base

# enable manually boosting of documents if there's a boost field available
index.boost.enable=true

# the field used to boost the document, if boost is enabled
elastic.boost.field=boost

# modifier to apply to the field value, can be one of: none, log,  log1p, log2p, ln, ln1p, ln2p, square, sqrt, or reciprocal
elastic.boost.modifier=log1p

# optional factor to multiply the field value with, defaults to 1
elastic.boost.factor=1

# the mode the scores are combined
elastic.boost.mode=sum

# the field containing the title of the document
index.field.title=title

# the field containing the summary/abstract of the document
index.field.summary=summary

# the fields to search in index as default
index.search.defaultFields=title,content

# define the fields not to be included within a record request
#index.fields.exclude=

# add custom analyzer decomp (using elasticsearch-analysis-decompound plugin)
index.analysis.filter.decomp.type=decompound
index.analysis.filter.german_stop.type=stop
index.analysis.filter.german_stop.stopwords=_german_
index.analysis.filter.german_stemmer.type=stemmer
index.analysis.filter.german_stemmer.language=light_german
index.analysis.analyzer.decomp.type=custom
index.analysis.analyzer.decomp.tokenizer=standard

index.analysis.analyzer.decomp.filter.0=lowercase
index.analysis.analyzer.decomp.filter.1=german_stop
index.analysis.analyzer.decomp.filter.2=german_normalization
index.analysis.analyzer.decomp.filter.3=german_stemmer
index.analysis.analyzer.decomp.filter.4=decomp
index.analysis.analyzer.decomp.filter.5=unique

index.analysis.analyzer.no_decomp.type=custom
index.analysis.analyzer.no_decomp.tokenizer=standard
index.analysis.analyzer.no_decomp.filter.0=lowercase
index.analysis.analyzer.no_decomp.filter.1=german_stop
index.analysis.analyzer.no_decomp.filter.2=german_normalization
index.analysis.analyzer.no_decomp.filter.3=german_stemmer
index.analysis.analyzer.no_decomp.filter.4=unique
